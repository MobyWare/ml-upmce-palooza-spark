{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest of Doom\n",
    "### By Ryan Dickson\n",
    "### Edited by Mohinder Dick\n",
    "> References go here for presentation version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from dateutil.parser import parse\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import StringIndexer, HashingTF, VectorAssembler, IDF\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up environment depend variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file path: file:///C:/Users/madick/Documents/Projects/ML/Source/UPMC/Pharmacy/visit_train_panda.csv.\n",
      "Test file path: file:///C:/Users/madick/Documents/Projects/ML/Source/UPMC/Pharmacy/visit_test_panda.csv.\n",
      "Pyspark path: None.\n"
     ]
    }
   ],
   "source": [
    "# Set up the path of the files and environment va\n",
    "\n",
    "if sc._conf.get('spark.master') == 'yarn-client' or sc._conf.get('spark.master') == 'yarn-cluster':\n",
    "    urn = 'hdfs://sparkdl04:8020/palooza/data/visit_train_panda.csv'\n",
    "    urnTest = 'hdfs://sparkdl04:8020/palooza/data/validate/visit_test_panda.csv'\n",
    "    \n",
    "    # Set up the path of the python pyspark should use\n",
    "    #os.environ['PYSPARK_PYTHON'] = '/opt/anaconda/bin/python'\n",
    "else:\n",
    "    urn = 'file:///C:/Users/%s/Documents/Projects/ML/Source/UPMC/Pharmacy/visit_train_panda.csv' % (os.getenv('USERNAME', 'dickm'))\n",
    "    urnTest = 'file:///C:/Users/%s/Documents/Projects/ML/Source/UPMC/Pharmacy/visit_test_panda.csv' % (os.getenv('USERNAME', 'dickm'))\n",
    "    #os.environ['PYSPARK_PYTHON'] = 'C:\\Users\\dickm\\AppData\\Local\\Continuum\\Anaconda2\\python.exe'\n",
    "\n",
    "# Used avoid issues in windows when reading text files.\n",
    "partitionNumber = 500\n",
    "\n",
    "print('Train file path: %s.\\nTest file path: %s.\\nPyspark path: %s.' % (urn, urnTest, os.environ.get('PYSPARK_PYTHON')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Spark\n",
    "\n",
    "This launches the notebook and provides the spark context in the variable *sc*. You can use the context to preview the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'spark.rdd.compress', u'True'), (u'spark.serializer.objectStreamReset', u'100'), (u'spark.master', u'local[*]'), (u'spark.submit.deployMode', u'client'), (u'spark.app.name', u'PySparkShell')]\n",
      "\n",
      "sum of 1 to 1000:  499500\n"
     ]
    }
   ],
   "source": [
    "print sc._conf.getAll()\n",
    "test = sc.parallelize(range(1000))\n",
    "print '\\nsum of 1 to 1000: ', test.reduce(lambda a, b: a+b )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added parallelism due to issue on windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[20] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chargesRDD = sc.textFile(urn, partitionNumber)\n",
    "\n",
    "#Get a new RDD with map function and lambda keyword. Remove header row.\n",
    "header = chargesRDD.take(1)[0]\n",
    "chargesRDD = chargesRDD.filter(lambda line: line!=header)\n",
    "chargesRDDSplit = chargesRDD.map(lambda line: line.replace('\"', '').split(','))\n",
    "chargesRDDSplit.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the test data\n",
    "\n",
    "Mo knows where it's at!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[23] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chargesRDDTEST = sc.textFile(urnTest, partitionNumber)\n",
    "   \n",
    "chargesRDDTEST = chargesRDD.filter(lambda line: line!=header)\n",
    "chargesRDDSplitTEST = chargesRDD.map(lambda line: line.replace('\"', '').split(','))\n",
    "chargesRDDSplitTEST.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training records is 279808.\n",
      "The number of test records is 279808\n",
      "First row of train:\n",
      "[u'\"HdBgCT1YkEl14280\",\"SHY\",436,\"I\",77,\"W\",\"M\",\"MS\",\"10/07/2014\",\"10/10/2014\",3,\"197.7\",\"SECOND MALIG NEO LIVE\",\"1\",10028']\n",
      "The first row of test:\n",
      "[u'\"HdBgCT1YkEl14280\",\"SHY\",436,\"I\",77,\"W\",\"M\",\"MS\",\"10/07/2014\",\"10/10/2014\",3,\"197.7\",\"SECOND MALIG NEO LIVE\",\"1\",10028']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#look at the data\n",
    "print ('The number of training records is %s.\\nThe number of test records is %s' % \n",
    "       (chargesRDD.count(), chargesRDDTEST.count()))\n",
    "print ('First row of train:\\n%s\\nThe first row of test:\\n%s\\n' % (chargesRDD.take(1), chargesRDDTEST.take(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* VisitID - Identifier for patient visit.\n",
    "* Hospital - Admitting hospital.\n",
    "* Dept_Code - department code.\n",
    "* PaymentType - I am guessing a payment type for visit.\n",
    "* Age - Age of the patient in years.\n",
    "* Race - De-identified race of the patient.\n",
    "* Gender - Gender (\"M\" - male, \"F\" - female)\n",
    "* FC - ?\n",
    "* ArriveDate - Date of admission. \n",
    "* DischargeDate - Date of discharge\n",
    "* LOS - length of patient stay in days.\n",
    "* DXCODE - Diagnosis code.\n",
    "* Description - Description of diagnosis\n",
    "* DispenseID - ?\n",
    "* DOC - ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Random Forest Model\n",
    "### We want to predict the length of stay (LOS) given the patient demographics, dxcode and deptcode, and day of the week admitted.\n",
    "\n",
    "Assumptions of feature relevance...\n",
    "* Dept_code categorical, some departments would have more serious patients than others\n",
    "* Day of the week, Patients admitted over weekend may require a longer length of stay to be seen by necessary staff\n",
    "* Dxcode, multiple per patient, may need to use PCA to reduce number (PCA is not always good before random forest, see references)\n",
    "* Demographics: age, gender and race \n",
    "\n",
    "\n",
    "We go through the following pipeline:\n",
    "* Encode/Extract features\n",
    "* Train the model\n",
    "* Evaluate the model on unseen data\n",
    "* Draw conclusions and make recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should not need to normalize the features for Random Forest, but bucketing may be needed to help with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dxcodeRDD = chargesRDDSplit.map(lambda line: (line[0], line[11])).groupByKey().distinct().cache()\n",
    "dxCodes = dxcodeRDD.values().flatMap(list).distinct()\n",
    "dxCodeCount = dxCodes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge(x, y):\n",
    "    \n",
    "    if x is not None: \n",
    "        x['dxCount'] += 1\n",
    "        if 'dxcode' in x:\n",
    "            x['dxcode'] = list(set(x['dxcode'] + y['dxcode']))\n",
    "        else:\n",
    "            x = y\n",
    "    else:\n",
    "        x = y\n",
    "    return x\n",
    "\n",
    "\n",
    "def mapAndFold(rdd):\n",
    "    return rdd.map(lambda line: (line[0], dict(\n",
    "             los=float(line[10]),\n",
    "             age=int(line[4]),\n",
    "             hospital_visit=line[1],\n",
    "             dept_code=line[2],\n",
    "             race=line[5], \n",
    "             gender_female=1 if line[6]=='F' else 0,    #Encode gender as boolean\n",
    "             dxcode=[line[11]],\n",
    "             admit_day=parse(line[8]).weekday(),\n",
    "             admit_month=parse(line[8]).month,\n",
    "             dxCount=1,\n",
    "             fc=line[7]\n",
    "            ))).foldByKey(None, merge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chargesByVisitRDD = mapAndFold(chargesRDDSplit)\n",
    "#df = chargesByVisitRDD.values().toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 15.0 failed 1 times, most recent failure: Lost task 1.0 in stage 15.0 (TID 3016, localhost): org.apache.spark.SparkException: Python worker did not connect back in time\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:136)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:65)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:134)\r\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:101)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:342)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:131)\r\n\t... 16 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\r\n\tat scala.Option.foreach(Option.scala:236)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:393)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\r\n\tat py4j.Gateway.invoke(Gateway.java:259)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.SparkException: Python worker did not connect back in time\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:136)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:65)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:134)\r\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:101)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:342)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:131)\r\n\t... 16 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-fa24392fd0c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchargesByVisitRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Applications\\spark-1.6.1-bin-hadoop2.6\\python\\pyspark\\rdd.pyc\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, num)\u001b[0m\n\u001b[0;32m   1295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m             \u001b[0mitems\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\spark-1.6.1-bin-hadoop2.6\\python\\pyspark\\context.pyc\u001b[0m in \u001b[0;36mrunJob\u001b[1;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[0;32m    937\u001b[0m         \u001b[1;31m# SparkContext#runJob.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 939\u001b[1;33m         \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    940\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\spark-1.6.1-bin-hadoop2.6\\python\\lib\\py4j-0.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    811\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m         return_value = get_return_value(\n\u001b[1;32m--> 813\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\spark-1.6.1-bin-hadoop2.6\\python\\pyspark\\sql\\utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Applications\\spark-1.6.1-bin-hadoop2.6\\python\\lib\\py4j-0.9-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    306\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    307\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    309\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 15.0 failed 1 times, most recent failure: Lost task 1.0 in stage 15.0 (TID 3016, localhost): org.apache.spark.SparkException: Python worker did not connect back in time\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:136)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:65)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:134)\r\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:101)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:342)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:131)\r\n\t... 16 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\r\n\tat scala.Option.foreach(Option.scala:236)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:393)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\r\n\tat py4j.Gateway.invoke(Gateway.java:259)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.SparkException: Python worker did not connect back in time\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:136)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:65)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:134)\r\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:101)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:342)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:131)\r\n\t... 16 more\r\n"
     ]
    }
   ],
   "source": [
    "chargesByVisitRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = chargesByVisitRDD.values().toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chargesByVisitRDDTEST = mapAndFold(chargesRDDSplitTEST)\n",
    "dfTEST = chargesByVisitRDD.values().toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stringIndexers = [\n",
    "    StringIndexer(inputCol=\"hospital_visit\", outputCol=\"hospitalIndex\"),\n",
    "    StringIndexer(inputCol=\"dept_code\", outputCol=\"deptIndex\"),\n",
    "    StringIndexer(inputCol=\"race\", outputCol=\"raceIndex\")\n",
    "]\n",
    "\n",
    "hashingTF = HashingTF(numFeatures=2*dxCodeCount, inputCol=\"dxcode\", outputCol=\"dxCodes\")\n",
    "idf = IDF(inputCol=\"dxCodes\", outputCol=\"idfDxCodes\", minDocFreq=10)\n",
    "\n",
    "mungePipeline = Pipeline(stages=stringIndexers + [hashingTF, idf])\n",
    "\n",
    "mungingModel = mungePipeline.fit(df)\n",
    "trainingData = mungingModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testingData = mungingModel.transform(dfTEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Munge it!\n",
    "String Indexers Need to have all values, so will need to fit combined traing and test data if unseen labels are present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "   inputCols=[\"age\", \n",
    "              \"deptIndex\", \n",
    "              \"gender_female\",\n",
    "              \"raceIndex\",\n",
    "              \"hospitalIndex\",\n",
    "              \"admit_day\",\n",
    "              \"admit_month\",\n",
    "              \"dxCount\",\n",
    "              \"idfDxCodes\"\n",
    "             ],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "transformedTrainingDF = assembler.transform(trainingData).select('features','los')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformedTestingDF = assembler.transform(testingData).select('features','los')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "Now we generate the training and test data. We use the ***seed*** function to ensure a repeatable split of the data between runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"los\",maxBins=1000, seed=1234)\n",
    "\n",
    "#Magic Numbers?\n",
    "rf.setNumTrees(100) \n",
    "rf.setMaxDepth(10) # Max of Spark is 30\n",
    "rf.setMinInstancesPerNode(5)\n",
    "rf.setFeatureSubsetStrategy('all')\n",
    "\n",
    "model = rf.fit(transformedTrainingDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model\n",
    "We evaluate the model on the unseen dataset that was not used to train the model. For reference here is the stats for los in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe('los').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "predictions = model.transform(transformedTestingDF).select('los','prediction')\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"los\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
